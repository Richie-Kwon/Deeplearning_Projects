{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handwriting digits dataset (MNIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size, # data set is big, binding batches! \n",
    "                                          shuffle=True,   # data is shuffle\n",
    "                                          drop_last=True) #if data has no information at the end, the data is taken away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers Node(or units) = 256 \n",
    "linear1 = torch.nn.Linear(784, 256, bias=True) #Input layer\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True) #Hidden layer\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True)  #output layer\n",
    "relu = torch.nn.ReLU() #Activation fuction is Relu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6645,  0.6646,  0.7159,  ..., -0.3040, -0.8945, -0.7977],\n",
       "        [-1.2045,  2.4545, -1.8073,  ..., -1.7139, -0.0451,  0.3864],\n",
       "        [ 0.3414,  0.3114, -1.9218,  ..., -0.4525, -0.6849,  0.9663],\n",
       "        ...,\n",
       "        [ 1.3915, -0.4048,  0.2338,  ..., -0.8257, -0.8397,  1.9816],\n",
       "        [ 1.0414,  0.2130, -0.0417,  ...,  1.7541, -0.6454, -0.0821],\n",
       "        [-0.1162, -1.2692,  0.8201,  ..., -0.8303, -0.5022,  0.0583]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialization\n",
    "torch.nn.init.normal_(linear1.weight) # xavier initialization torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.normal_(linear2.weight) # torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.normal_(linear3.weight) # torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #Adam Optimiser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 129.413299561\n",
      "Epoch: 0002 cost = 36.166305542\n",
      "Epoch: 0003 cost = 23.086570740\n",
      "Epoch: 0004 cost = 15.989409447\n",
      "Epoch: 0005 cost = 11.555795670\n",
      "Epoch: 0006 cost = 8.507574081\n",
      "Epoch: 0007 cost = 6.359047413\n",
      "Epoch: 0008 cost = 4.775888443\n",
      "Epoch: 0009 cost = 3.597442627\n",
      "Epoch: 0010 cost = 2.749284983\n",
      "Epoch: 0011 cost = 2.104791164\n",
      "Epoch: 0012 cost = 1.626359701\n",
      "Epoch: 0013 cost = 1.245584369\n",
      "Epoch: 0014 cost = 1.025017500\n",
      "Epoch: 0015 cost = 0.755999088\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9465000033378601\n",
      "Label:  8\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "import matplotlib.pyplot as plt\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "    \n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
